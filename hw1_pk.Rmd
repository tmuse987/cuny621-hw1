---
title: "Data 621 - Homework 1"
author: "Tommy Jenkins, Violeta Stoyanova, Todd Weigel, Peter Kowalchuk"
date: "September, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

```{r echo=FALSE}
library(ggplot2)
library(tidyr)
library(MASS)

#setwd("l:/school/cuny/621/hw1")
mbTrain <- read.csv("moneyball-training-data.csv")
mbEval <- read.csv("moneyball-evaluation-data.csv")

```

#Moneyball Dataset Analysis and Modeling

###1. DATA EXPLORATION

```{r echo=FALSE}
colsTrain<-ncol(mbTrain)
colsEval<-ncol(mbEval)
missingCol<-colnames(mbTrain)[!(colnames(mbTrain) %in% colnames(mbEval))]
```

The dataset consists of two data files: training and evaluation. The training dataset contains `r colsTrain` columns, while the evaluation dataset contains `r colsEval`. The evaluation dataset is missing column `r missingCol`. We will start by exploring the training data set since it will be the one used to generate the regression model.

```{r echo=FALSE}
text<-"a test"
if(all(apply(mbTrain,2,function(x) is.numeric(x)))==TRUE) {
  text<-"all data is numeric"
} else {
  text<-"not all data is numeric"
}
maxMeanMedianDiff<-round(max(abs(sapply(mbTrain, median, na.rm = T) - sapply(mbTrain, mean, na.rm = T))*100/(sapply(mbTrain, max, na.rm = T)-sapply(mbTrain, min, na.rm = T))),2)
```

First we see that `r text`. 

```{r echo=FALSE}
nas<-as.data.frame(sapply(mbTrain, function(x) sum(is.na(x))))
nasp<-as.data.frame(sapply(mbTrain, function(x) round(sum(is.na(x))/nrow(mbTrain)*100,1)))
colnames(nas)<-c("name")
maxna<-max(nas)
maxnaname<-rownames(nas)[nas$name==maxna]
percent<-round(maxna/nrow(mbTrain)*100,1)
```

An important aspec of any dataset is to determine how much, if any, data is missing. We look at all the variables to see which if any have missing data. We look at the percentages of the data that are missing:

```{r echo=FALSE}
#sapply(mbTrain, function(x) sum(is.na(x)))
sapply(mbTrain, function(x) round(sum(is.na(x))/nrow(mbTrain)*100,1))
```

From this result we can see how several variables have a number of missing values. The maximum number of missing values was `r maxna` in the `r maxnaname` variable. This is a significant amount of missing data representing `r percent`% of that data. 

With missing data asseced, we can look into descriptive statistics in more detail. Interestingly we find that the difference between means and medians is fairly small for all data columns. The maximum difference is in fact only `r maxMeanMedianDiff`%. This means that we are to expect the distributions of this data to be fairly uniform. To visualize this we plot histograms for each data. 

```{r echo=FALSE}
#summary(mbTrain)
```

```{r echo=FALSE,message=FALSE}
attach(mbTrain)
ggplot(gather(mbTrain), aes(value)) +
    geom_histogram(bins = 20) +
    facet_wrap(~key, scales = "free_x")

```

The plot of distributions does show fairly uniform data, but it also show the potential precense of outliers in at least two of the predictors. This is not the best way to vizualise ouliers. Instead we identify the predictors which seem to have outliers by looking at the scattered and box plots. Two variables with outliers appera to be TEAM_PITCHING_H, TEAM_PITCHING_SO, TEAM_PITCHING_BB and TEAM_FIELDING_E. We highlight these variables from the desity plots since we can see most of the data concentrated at the lower end of the scales which show tailing off to high values. 

**TEAM_PITCHING_H**

```{r echo=FALSE,message=FALSE}
plot(mbTrain$TEAM_PITCHING_H)
boxplot(mbTrain$TEAM_PITCHING_H)
summary(mbTrain$TEAM_PITCHING_H)
max<-summary(mbTrain$TEAM_PITCHING_H)[6]
median<-round(summary(mbTrain$TEAM_PITCHING_H)[3],1)
spread<-round(as.numeric(summary(mbTrain$TEAM_PITCHING_H)[4]-summary(mbTrain$TEAM_PITCHING_H)[3]),0)
```

From the summary for this variable we see that the maximum is `r max`, which is substantially far from the median of `r median`. We can also see a wide spread between mean and median of `r spread`. But we know the maximum is not a realistic number. We can compare the numbers of pitching hits, to the number of batting hits, summary for which is shown below:

```{r echo=FALSE,message=FALSE}
summary(mbTrain$TEAM_BATTING_H)
maxb<-summary(mbTrain$TEAM_BATTING_H)[6]
spreadb<-round(as.numeric(summary(mbTrain$TEAM_BATTING_H)[4]-summary(mbTrain$TEAM_BATTING_H)[3]),0)
```

For batting the maximum is `r maxb`, much lower than `r max`. We expect these two variables to somewhat equal values since one is the reciprocal of the other. As a saminity check of the distribution of the batting variable, we now see the mean and median much closer together with a spread of only `r spreadb`.

**TEAM_PITCHING_SO**

```{r echo=FALSE,message=FALSE}
plot(mbTrain$TEAM_PITCHING_SO)
boxplot(mbTrain$TEAM_PITCHING_SO)
summary(mbTrain$TEAM_PITCHING_SO)
max<-summary(mbTrain$TEAM_PITCHING_SO)[6]
median<-round(summary(mbTrain$TEAM_PITCHING_SO)[3],1)
spread<-round(as.numeric(summary(mbTrain$TEAM_PITCHING_SO)[4]-summary(mbTrain$TEAM_PITCHING_SO)[3]),0)
```

Again looking at the maximum we find it is unreasonably high at `r max`, which again is substantially far from the median of `r median`. Again this variable has a reciprocal in TEAM_BATTING_SO. Comparing agaisnt it confirms the outliers.

```{r echo=FALSE,message=FALSE}
summary(mbTrain$TEAM_BATTING_SO)
maxb<-summary(mbTrain$TEAM_BATTING_SO)[6]
spreadb<-round(as.numeric(summary(mbTrain$TEAM_BATTING_SO)[3]-summary(mbTrain$TEAM_BATTING_SO)[4]),1)
```

We see that or batting the maximum is `r maxb`, much lower than `r max`. As before as a saminity check of the distribution of the batting variable, we now see the mean and median much closer together with a spread of only `r spreadb`.

**TEAM_PITCHING_BB**

```{r echo=FALSE,message=FALSE}
plot(mbTrain$TEAM_PITCHING_BB)
boxplot(mbTrain$TEAM_PITCHING_BB)
summary(mbTrain$TEAM_PITCHING_BB)
max<-summary(mbTrain$TEAM_PITCHING_BB)[6]
median<-round(summary(mbTrain$TEAM_PITCHING_BB)[3],1)
spread<-round(as.numeric(summary(mbTrain$TEAM_PITCHING_BB)[4]-summary(mbTrain$TEAM_PITCHING_BB)[3]),0)
```

Again looking at the maximum we find it is unreasonably high at `r max`, which again is substantially far from the median of `r median`. Again this variable has a reciprocal in TEAM_BATTING_SO. Comparing agaisnt it confirms the outliers.

```{r echo=FALSE,message=FALSE}
summary(mbTrain$TEAM_BATTING_BB)
maxb<-summary(mbTrain$TEAM_BATTING_BB)[6]
spreadb<-round(as.numeric(summary(mbTrain$TEAM_BATTING_BB)[3]-summary(mbTrain$TEAM_BATTING_BB)[4]),1)
```

We see that or batting the maximum is `r maxb`, much lower than `r max`. As before as a saminity check of the distribution of the batting variable, we now see the mean and median much closer together with a spread of only `r spreadb`.

**TEAM_FIELDING_E**

```{r echo=FALSE,message=FALSE}
plot(mbTrain$TEAM_FIELDING_E)
boxplot(mbTrain$TEAM_FIELDING_E)
summary(mbTrain$TEAM_FIELDING_E)
max<-summary(mbTrain$TEAM_FIELDING_E)[6]
median<-round(summary(mbTrain$TEAM_FIELDING_E)[3],1)
spread<-round(as.numeric(summary(mbTrain$TEAM_FIELDING_E)[4]-summary(mbTrain$TEAM_FIELDING_E)[3]),0)

```

Again looking at the maximum we find it is unreasonably high at `r max`, which again is substantially far from the median of `r median`. 



####Correlation
Looking at correlation of variables to number of wins provides some interesting data.  We find some correlations that make sense from what might assume with subject knowledge of base, e.g., the number of hits and number of variables both have significant positive correlation with Wins and other statistics like stolen bases, while still positive, are not so strongly related.  What is surprising though, are the pitching statistics.  We would assume that a team that allowed the opposing team more hits, would lose more games (and win less), but that is not what the data shows us.  Perhaps there are outliers swaying the correlation.

Regardless, we can use some of these correlations to drive initial models later, in terms of likely fields to choose for an effective model.



```{r echo = FALSE, message=FALSE}
cor(mbTrain$TARGET_WINS, mbTrain[-c(1)])
```

###2. DATA PREPARATION

First task under data preparation will be to eliminate all missing data. In the Data Exploration section we found one variable, `r maxnaname` with an exceptionaly high percentage of missing data, so we commence by eliminating this variable.  We also remove the "INDEX" column as that is not used.

```{r echo=FALSE}
mbTrain <- mbTrain[, -which(names(mbTrain) %in% c("INDEX", maxnaname))]
```

Next task is to handle missing data in the other variables. Here, becouse the percentages of missing data are lower, we can replace missing data with the median. We prefer replacing with median instead of mean because the latter is more sensitive to outliers. So we get a clean dataset without missing values.

Note we also consider zeros to be missing data.  Since each row is a season of data for a given baseball team, it would be extraordinarily unlikely that any of these statistics would have zero as an actual value.  Therefore we are assuming zero is another indicator of missing value and we will transform them into a median value.

```{r echo=FALSE}

for(i in 2:ncol(mbTrain))
{
    idx <- mbTrain[i]==0 | is.na(mbTrain[i])  #find index of all rows that are zero or na
    mbTrain[i][idx] <- (floor(median(mbTrain[[i]][mbTrain[[i]]!=0], na.rm = TRUE))) #remove zeros and na's from median equation
}

#don't need these rows anymore, above loop takes care of it
# mbTrain$TEAM_BASERUN_CS[is.na(mbTrain$TEAM_BASERUN_CS)] <- median(mbTrain$TEAM_BASERUN_CS, na.rm=TRUE)
# mbTrain$TEAM_BATTING_SO[is.na(mbTrain$TEAM_BATTING_SO)] <- median(mbTrain$TEAM_BATTING_SO, na.rm=TRUE)
# mbTrain$TEAM_BASERUN_SB[is.na(mbTrain$TEAM_BASERUN_SB)] <- median(mbTrain$TEAM_BASERUN_SB, na.rm=TRUE)
# mbTrain$TEAM_PITCHING_SO[is.na(mbTrain$TEAM_PITCHING_SO)] <- median(mbTrain$TEAM_PITCHING_SO, na.rm=TRUE)

```

In the exploratory phase we also identified several variables with outliers. Outliers will be substituted with median. Again we choose median becouse it is less influenced by these outliers. What cutoff to use to tag an outlier reading could be a 3 standard deviation from the mean, or 1.5 time the inter quartile range, but in this case becouse these variables have reciprocals as seen in the exploratory phase, we will use the maximum reading of those variables.

**TEAM_PITCHING_H**

```{r echo=FALSE}
mbTrain$TEAM_PITCHING_H[mbTrain$TEAM_PITCHING_H>max(mbTrain$TEAM_BATTING_H)] <- median(mbTrain$TEAM_PITCHING_H, na.rm=TRUE)

plot(mbTrain$TEAM_PITCHING_H)
boxplot(mbTrain$TEAM_PITCHING_H)
summary(mbTrain$TEAM_PITCHING_H)
max<-summary(mbTrain$TEAM_PITCHING_H)[6]
median<-
    
spread<-round(as.numeric(summary(mbTrain$TEAM_PITCHING_H)[4]-summary(mbTrain$TEAM_PITCHING_H)[3]),0)
```

From the summary we now see that the maximum is `r max`, which is a much more reasonable number. We can also see a wide spread between mean and median of `r spread`, indicating a more normal distribution than before.

**TEAM_PITCHING_SO**

```{r echo=FALSE}
mbTrain$TEAM_PITCHING_SO[mbTrain$TEAM_PITCHING_SO>max(mbTrain$TEAM_BATTING_SO)] <- median(mbTrain$TEAM_PITCHING_SO, na.rm=TRUE)

plot(mbTrain$TEAM_PITCHING_SO)
boxplot(mbTrain$TEAM_PITCHING_SO)
summary(mbTrain$TEAM_PITCHING_SO)
max<-summary(mbTrain$TEAM_PITCHING_SO)[6]
median<-round(summary(mbTrain$TEAM_PITCHING_SO)[3],1)
spread<-round(as.numeric(summary(mbTrain$TEAM_PITCHING_SO)[4]-summary(mbTrain$TEAM_PITCHING_SO)[3]),0)
```

From the summary we now see that the maximum is `r max`, which is a much more reasonable number. We can also see a wide spread between mean and median of `r spread`, indicating a more normal distribution than before.

```{r echo=FALSE,message=FALSE}
attach(mbTrain)
ggplot(gather(mbTrain), aes(value)) +
    geom_histogram(bins = 20) +
    facet_wrap(~key, scales = "free_x")

```

**New Variables**

With a clean dataset, we can now start looking at what predictor variables can be combined and what new statistics can be derived.

On the batting side we can start by adding a variable for single hits since the dataset has a variable for all 4 kinds of hits.

TEAM_BATTING_HS = TEAM_BATTING_H - (TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR)

```{r echo = FALSE, message=FALSE}
mbTrain$TEAM_BATTING_HS<-mbTrain$TEAM_BATTING_H - (mbTrain$TEAM_BATTING_2B + mbTrain$TEAM_BATTING_3B + mbTrain$TEAM_BATTING_HR)
summary(mbTrain$TEAM_BATTING_HS)
```

There are other popular baseball statistics which are regulary calculated. The data given is limited, so it won't be possible to make all these calculations. But we can use the data given to calculate some statistics that resemble some of the common baseball measurments. 

The number of times a batter reaches base can be calculated as Times On Base:

**Times On Base**

TOB = Base Hits + Walks + Hits by Pitch 
TOB = ( TEAM_BATTING_H - TEAM_BATTING_HR ) + TEAM_BATTING_BB + TEAM_BATTING_HBP 
TOB = TEAM_BATTING_TOB

In our case we do not have TEAM_BATTING_HBP. We deleted this predictor since it didn't contain enough data, so we will not include this term in calculating TOB. 

TEAM_BATTING_TOB Summary:
```{r echo = FALSE, message=FALSE}
mbTrain$TEAM_BATTING_TOB<-mbTrain$TEAM_BATTING_H - mbTrain$TEAM_BATTING_HR# + mbTrain$TEAM_BATTING_BB
summary(mbTrain$TEAM_BATTING_TOB)
```

**On Base Percentage**

If we devide this statistic by the times a batter appears on plate, we have a ratio for On Base Percentage. Batter apperances on plate is not a statistic that was given, but we can assumes it would the similar to the number of times a batter produces a hit and the times of strikeouts.

OBP = TOB / ( Base Hits + Walks + Hits by Pitch + Strikeouts ) 
OBP = TEAM_BATTING_TOB / (( TEAM_BATTING_H - TEAM_BATTING_HR ) + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BATTING_SO )
OBP = TEAM_BATTING_OBP

Same as before TEAM_BATTING_HBP is missing so we do not include it. 

TEAM_BATTING_OBP Summary
```{r echo = FALSE, message=FALSE}
mbTrain$TEAM_BATTING_OBP<-mbTrain$TEAM_BATTING_TOB / (( mbTrain$TEAM_BATTING_H - mbTrain$TEAM_BATTING_HR ) + mbTrain$TEAM_BATTING_BB + mbTrain$TEAM_BATTING_SO )
summary(mbTrain$TEAM_BATTING_OBP)
```


**Batting Average**

This statistics is calculated as the number of batter hits devided by times at bat or on plate. With our dataset we will compute times at bat as the sum of a batters hits and strike out, same as we did on the privious calculated variable since the number of Hits by Pitch is not available:

AVG = Hits / (Hits + Walks + Strikeouts)
AVG = TEAM_BATTING_H / ( TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BATTING_SO )
AVG = TEAM_BATTING_BAVG

TEAM_BATTING_BAVG Summary
```{r echo = FALSE, message=FALSE}
mbTrain$TEAM_BATTING_BAVG<-mbTrain$TEAM_BATTING_H / ( mbTrain$TEAM_BATTING_H + mbTrain$TEAM_BATTING_BB + mbTrain$TEAM_BATTING_SO )
summary(mbTrain$TEAM_BATTING_BAVG)
```

**Slugging Percentage**

A shortcoming of the previous statistic is that it weights any kind of hits equally. To account for the fact that some hits are more beneficial or carry higher weight we can calculate a slugging percentage by multipliying each kind of hit by an increasing number.

SLG = ( Single Hits + 2 * Double Hits + 3 * Tripple Hits + 4 * Home Runs ) / (Hits + Walks + Strikeouts)
TEAM_BATTING_SLG = ( ( TEAM_BATTING_H - TEAM_BATTING_2B - TEAM_BATTING_3B - TEAM_BATTING_HR )  + 2 * TEAM_BATTING_2B + 3 * TEAM_BATTING_3B + 4 * TEAM_BATTING_HR ) / ( mbTrain$TEAM_BATTING_H + mbTrain$TEAM_BATTING_BB + mbTrain$TEAM_BATTING_SO )

TEAM_BATTING_SLG Summary
```{r echo = FALSE, message=FALSE}
mbTrain$TEAM_BATTING_SLG<-( ( mbTrain$TEAM_BATTING_H - mbTrain$TEAM_BATTING_2B - mbTrain$TEAM_BATTING_3B - mbTrain$TEAM_BATTING_HR )  + 2 * mbTrain$TEAM_BATTING_2B + 3 * mbTrain$TEAM_BATTING_3B + 4 * mbTrain$TEAM_BATTING_HR ) / ( mbTrain$TEAM_BATTING_H + mbTrain$TEAM_BATTING_BB + mbTrain$TEAM_BATTING_SO )
summary(mbTrain$TEAM_BATTING_SLG)
```

**Training and Test**

Lastly, before we create models, lets divide data into test and training sets, with 80% for training, 20% for test.  This way we have a method to validate our models.

```{r echo = FALSE, message=FALSE}
set.seed(42)
sample <- sample.int(n=nrow(mbTrain), size = floor(.80*nrow(mbTrain)),replace=F)
train <- mbTrain[sample,]
test <- mbTrain[-sample,]

```

###3. BUILD MODELS

**Batting only model**

Model using batting hits as predictor. TEAM_BATTING_H includes single, doubles and tripples.

```{r echo = FALSE, message=FALSE}
###Note, this doesn't include TEAM_BATTING_BB (base on balls, TEAM_BATTING_H includes hits, double, triples and hr).  Also doesn't include HPB, but since so many were missing from there, doesn't matter for that.
attach(train)
bat_mod_allHits<-lm(TARGET_WINS~TEAM_BATTING_H,train)
summary(bat_mod_allHits)
plot(mbTrain$TEAM_BATTING_H,mbTrain$TARGET_WINS)
abline(bat_mod_allHits)
plot(TARGET_WINS,residuals(bat_mod_allHits))
hist(bat_mod_allHits$residuals)
qqnorm(bat_mod_allHits$residuals)
qqline(bat_mod_allHits$residuals)
#ggplot(bat_mod, aes(x= seq(1:nrow(mbTrain)), y= .resid)) +geom_point()
ggplot(bat_mod_allHits, aes(x= .fitted, y= .resid)) +geom_point()
```

Model using only single hits. 

```{r echo = FALSE, message=FALSE}
attach(train)
bat_mod_single_Hits<-lm(TARGET_WINS~(TEAM_BATTING_H-TEAM_BATTING_2B-TEAM_BATTING_3B-TEAM_BATTING_HR),train)
summary(bat_mod_single_Hits)
plot((mbTrain$TEAM_BATTING_H-mbTrain$TEAM_BATTING_2B-mbTrain$TEAM_BATTING_3B-mbTrain$TEAM_BATTING_HR),mbTrain$TARGET_WINS)
abline(bat_mod_single_Hits)
plot(TARGET_WINS,residuals(bat_mod_single_Hits))
hist(bat_mod_single_Hits$residuals)
qqnorm(bat_mod_single_Hits$residuals)
qqline(bat_mod_single_Hits$residuals)
#ggplot(bat_mod, aes(x= seq(1:nrow(mbTrain)), y= .resid)) +geom_point()
ggplot(bat_mod_single_Hits, aes(x= .fitted, y= .resid)) +geom_point()
```

Model using single hits and strikes by batter. 

```{r echo = FALSE, message=FALSE}
attach(train)
bat_mod_single_Hits_strikes<-lm(TARGET_WINS~TEAM_BATTING_H-TEAM_BATTING_2B-TEAM_BATTING_3B-TEAM_BATTING_HR+TEAM_BATTING_SO,train)
summary(bat_mod_single_Hits_strikes)
plot((mbTrain$TEAM_BATTING_H-mbTrain$TEAM_BATTING_2B-mbTrain$TEAM_BATTING_3B-mbTrain$TEAM_BATTING_HR),mbTrain$TARGET_WINS)
abline(bat_mod_single_Hits_strikes)
plot(TARGET_WINS,residuals(bat_mod_single_Hits_strikes))
hist(bat_mod_single_Hits_strikes$residuals)
qqnorm(bat_mod_single_Hits_strikes$residuals)
qqline(bat_mod_single_Hits_strikes$residuals)
#ggplot(bat_mod, aes(x= seq(1:nrow(mbTrain)), y= .resid)) +geom_point()
ggplot(bat_mod_single_Hits_strikes, aes(x= .fitted, y= .resid)) +geom_point()
```


**Pitching only model**

Combine all pitching variables.

```{r echo = FALSE, message=FALSE}
pitch_mod<-lm(TARGET_WINS~TEAM_PITCHING_H+TEAM_PITCHING_HR,train)
summary(pitch_mod)
plot(TEAM_PITCHING_H+TEAM_PITCHING_HR, TARGET_WINS)
ggplot(train, aes(x = TEAM_PITCHING_HR + TEAM_PITCHING_H, y = TARGET_WINS)) +
    geom_point() + 
    geom_smooth(aes(y=predict(pitch_mod)))
    
#abline(pitch_mod)
plot(TARGET_WINS,residuals(pitch_mod))
abline(0,0)
hist(pitch_mod$residuals)
qqnorm(pitch_mod$residuals)
qqline(pitch_mod$residuals)
ggplot(pitch_mod, aes(x= .fitted, y= .resid)) +geom_point()
```

```{r echo = FALSE, message=FALSE}

train$HITS_NOHR <- TEAM_BATTING_H - TEAM_BATTING_HR
attach(train)

hits_NOHR_Mod <- lm(TARGET_WINS ~ HITS_NOHR)
summary(hits_NOHR_Mod)
plot(HITS_NOHR, TARGET_WINS)
abline(hits_NOHR_Mod)
hist(hits_NOHR_Mod$residuals)
qqnorm(hits_NOHR_Mod$residuals)
qqline(hits_NOHR_Mod$residuals)
ggplot(hits_NOHR_Mod, aes(x= .fitted, y= .resid)) +geom_point()


```

```{r echo = FALSE, message=FALSE}
#making a new column with the addition of these 3 doesn't work well, should be seperated in the model
#train$HITS_BB_ERR_NOHR <- HITS_NOHR + TEAM_BATTING_BB + TEAM_FIELDING_E

hitsNoHR_bb_e_mod <- lm(TARGET_WINS~ HITS_NOHR + TEAM_BATTING_BB + TEAM_FIELDING_E,train)
summary(hitsNoHR_bb_e_mod)
plot((HITS_NOHR + TEAM_BATTING_BB + TEAM_FIELDING_E), train$TARGET_WINS)
abline(hitsNoHR_bb_e_mod)
hist(hitsNoHR_bb_e_mod$residuals)
qqnorm(hitsNoHR_bb_e_mod$residuals)
qqline(hitsNoHR_bb_e_mod$residuals)
ggplot(hitsNoHR_bb_e_mod, aes(x= .fitted, y= .resid)) +geom_point()
```
Best in terms of residuals and Rsquared
Hits, BB, and Fielding Errors.  Plost look good except for short tailed issues in the QQ plot.

```{r echo = FALSE, message=FALSE}


#making a new column with the addition of these 3 doesn't work well, should be seperated in the model
#train$HITS_BB_ERR_NOHR <- TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_FIELDING_E

hits_bb_e_mod <- lm(TARGET_WINS~ TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_FIELDING_E, train)
summary(hits_bb_e_mod)
plot((TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_FIELDING_E), train$TARGET_WINS)
abline(hits_bb_e_mod)
hist(hits_bb_e_mod$residuals)
qqnorm(hits_bb_e_mod$residuals)
qqline(hits_bb_e_mod$residuals)
ggplot(hits_bb_e_mod, aes(x= .fitted, y= .resid)) +geom_point()
```

Attempt at boxcox, didn't achieve better results in R squared (not SE not directly comparable due to adjustment with boxcox)  The QQ plot seems to look a bit better as the negative quantiles are much closer to the line.
Box Cox

```{r echo = FALSE, message=FALSE}
boxcox(hits_bb_e_mod, lambda = seq(1.2,1.45, 0.05))
lambda <- 1.33
TARGET_WINS_BC <- ((TARGET_WINS^lambda)-1)/lambda
TEAM_BATTING_H_BC <- ((TEAM_BATTING_H^lambda)-1)/lambda
TEAM_BATTING_BB_BC <- ((TEAM_BATTING_BB^lambda)-1)/lambda
TEAM_FIELDING_E_BC <- ((TEAM_FIELDING_E^lambda)-1)/lambda
#hits_bb_e_mod_BC <- lm(TARGET_WINS_BC ~ TEAM_BATTING_H_BC + TEAM_BATTING_BB_BC + TEAM_FIELDING_E_BC)
hits_bb_e_mod_BC <- lm(TARGET_WINS_BC ~ TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_FIELDING_E)
summary(hits_bb_e_mod_BC)
#plot((TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_FIELDING_E), train$TARGET_WINS)
#abline(hits_bb_e_mod_bc)
hist(hits_bb_e_mod_BC$residuals)
qqnorm(hits_bb_e_mod_BC$residuals)
qqline(hits_bb_e_mod_BC$residuals)
ggplot(hits_bb_e_mod_BC, aes(x= .fitted, y= .resid)) +geom_point()
```


###4. SELECT MODELS

###APPENDIX




find counts of na's
notice that #hbp and cs (hit by pitch and caught stealing) have very large numbers of missing values, probably shouldn't use, 
and knowing baseball, probably minor impact on wins regardless, so remove those columns...
```{r echo = FALSE, message=FALSE}
sapply(mbTrain, function(x) sum(is.na(x)))

#remove those two columns, plus the index colume which we don't need
mbTrain <- mbTrain[, -which(names(mbTrain) %in% c("INDEX", "TEAM_BATTING_HBP", "TEAM_BASERUN_CS"))]
```


convert NA's to -1 for now so we can run test on zero's as zero's for any of these stats clearly is inaccurate and eqivalent to an NA

Number of zeros fields is not so bad, but lets not replace them until we check for outliers and convert NA's back to -1
```{r echo = FALSE, message=FALSE}
mbTrain[is.na(mbTrain)] <- -1
sapply(mbTrain, function(x) sum(x == 0))
```


Running summary we can see that there are some really big outliers (e.g., 19278 Strikeouts in one year?, that would be 119 per game....) at initial glance (can always revisit), looks like Pitching_Hits, Pitching_BB, Pitching_SO and Fielding Errors all have outliers that 
are not realistic values
```{r echo = FALSE, message=FALSE}
summary(mbTrain)

#looking at top values we can see that there maybe a number of years that are unrealistic
head(sort(mbTrain$TEAM_PITCHING_H, decreasing = TRUE))
head(sort(mbTrain$TEAM_PITCHING_BB, decreasing = TRUE))
head(sort(mbTrain$TEAM_PITCHING_SO, decreasing = TRUE))
head(sort(mbTrain$TEAM_FIELDING_E, decreasing = TRUE))
```

Let's plot to see where outliers are

```{r echo = FALSE, message=FALSE}
plot(mbTrain$TEAM_PITCHING_H)
boxplot(mbTrain$TEAM_PITCHING_H)
plot(mbTrain$TEAM_PITCHING_BB)
boxplot(mbTrain$TEAM_PITCHING_BB)
plot(mbTrain$TEAM_PITCHING_SO)
boxplot(mbTrain$TEAM_PITCHING_SO)
plot(mbTrain$TEAM_FIELDING_E)
boxplot(mbTrain$TEAM_FIELDING_E)
```

There are a lot of rows with pitching hits greater than 3000 (there was max of 2554 hits by batting team, so a limit of 3000 hits (18.5 avg per game) by a pitching team doesn't seem so unreasonable as max)we see 86, these should probably be tossed and replaced with median (mean?)
```{r echo = FALSE, message=FALSE}
sum(mbTrain$TEAM_PITCHING_H > 3000)
```
Using same idea for base on balls, max for batting was 878, so perhaps a 1200 max for pitching (7.5 avg a game) might be reasonable, so 10 rows like this.
```{r echo = FALSE, message=FALSE}
sum(mbTrain$TEAM_PITCHING_BB > 1200)
```

for strikeouts, batting max of 1399, so perhaps 1800 for pitching max, and we have 9 rows like this.
```{r echo = FALSE, message=FALSE}
sum(mbTrain$TEAM_PITCHING_SO > 1800)
```

For fielding errors, there is no corresponding number to validate against (like with pitching compared to batting), but if we use a plausible limit of about 10 per game (which is still really high we can eliminate clear outliers).
```{r echo = FALSE, message=FALSE}
sum(mbTrain$TEAM_FIELDING_E > 1600)
```

Now that we have identified them, let's replace all these values
```{r echo = FALSE, message=FALSE}
mbTrain$TEAM_PITCHING_H[mbTrain$TEAM_PITCHING_H >3000] <- 0
mbTrain$TEAM_PITCHING_BB[mbTrain$TEAM_PITCHING_BB >1200] <- 0
mbTrain$TEAM_PITCHING_SO[mbTrain$TEAM_PITCHING_SO >1800] <- 0
mbTrain$TEAM_FIELDING_E[mbTrain$TEAM_FIELDING_E >1600] <- 0
```
Now lets replace all zeros, plus the -1's we had put in earlier for for the na's.

We will use median for those values.

```{r echo = FALSE, message=FALSE}
for(i in 2:ncol(mbTrain))
{
    idx <- mbTrain[i]<=0
    mbTrain[i][idx] <- median(mbTrain[[i]])
}

```


Do some correlation
```{r echo = FALSE, message=FALSE}
cor(mbTrain$TARGET_WINS, mbTrain[-c(1)])
```

Do some basic plots to start looking at data:

```{r echo = FALSE, message=FALSE}
attach(mbTrain)
ggplot(mbTrain, aes(y=TEAM_BATTING_H, x= 1)) + geom_boxplot()
boxplot(TARGET_WINS)
#note appears reasonably normally distributed
ggplot() + geom_histogram(aes(x = TARGET_WINS))
ggplot() + geom_histogram(aes(x = TEAM_BATTING_H))


ggplot(gather(mbTrain), aes(value)) +
    geom_histogram(bins = 20) +
    facet_wrap(~key, scales = "free_x")

```

Fit a couple really simple models just to explore, one with everything, one with just home runs against wins.

```{r echo = FALSE, message=FALSE}
lmFit <- lm(TARGET_WINS ~., data = mbTrain)
summary(lmFit)
lmFit <- lm(TARGET_WINS ~ TEAM_BATTING_HR, data = mbTrain)

summary(lmFit)
```

Let's plot hits against wins as that field should highest correlation.

```{r echo = FALSE, message=FALSE}
lmFitH <- lm(TARGET_WINS ~ TEAM_BATTING_H)
ggplot(mbTrain, aes(x= TEAM_BATTING_H, y = TARGET_WINS)) + 
    geom_point() + 
    geom_smooth(method = "lm", se= FALSE)
```
Plot Residuals

```{r echo = FALSE, message=FALSE}
#vs index
ggplot(lmFitH, aes(x= seq(1:nrow(mbTrain)), y= .resid)) +geom_point()
#vs fitted value
ggplot(lmFitH, aes(x= .fitted, y= .resid)) +geom_point()
```



```
